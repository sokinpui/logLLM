# logLLM CLI: `normalize-ts` Command

The `normalize-ts` command is used to process log data that has already been parsed and stored in Elasticsearch by the `es-parse run` command (i.e., logs residing in `parsed_log_<group_name>` indices). Its primary goal is to standardize timestamp information.

**Prerequisites:**

- Elasticsearch must be running (`python -m src.logllm db start`).
- Parsed logs must exist in `parsed_log_<group_name>` indices, generated by `python -m src.logllm es-parse run ...`.

**Base command:** `python -m src.logllm normalize-ts <action> [OPTIONS]`

See also: [Global Options](./global_options.md)

---

## Functionality

The `normalize-ts run` action performs the following for each selected group:

1.  **Reads Parsed Logs:** It scrolls through documents in the `parsed_log_<group_name>` index.
2.  **Timestamp Discovery:** For each document, it intelligently searches for potential timestamp fields. This includes looking for fields commonly named by Grok patterns (e.g., `event_timestamp`, `raw_event_timestamp`, `timestamp`, `SYSLOGTIMESTAMP`) or combinations of date/time part fields.
3.  **Parsing and Normalization:**
    - It uses the `dateutil` library to parse the discovered timestamp string(s) into Python `datetime` objects. It can handle a wide variety of common timestamp formats.
    - The parsed `datetime` object is then normalized to **UTC**.
    - This UTC `datetime` is formatted into a standard **ISO 8601 string** (e.g., `YYYY-MM-DDTHH:MM:SS.sssZ`).
4.  **Updates Document:** The original document is updated:
    - The standardized ISO 8601 timestamp string is placed in the `@timestamp` field.
    - A `timestamp_normalized_details` field is added, containing information about the normalization process (status, original data used, etc.).
5.  **Stores in New Index:** The modified document (with the normalized `@timestamp`) is indexed into a new Elasticsearch index named `normalized_parsed_log_<group_name>`.
    - This ensures that the original parsed data remains untouched.
    - The new index is created with an explicit mapping for the `@timestamp` field to be of `date` type.
    - Documents are indexed using their original `_id`, so re-running the normalization for a group will overwrite existing documents in the `normalized_parsed_log_<group_name>` index.

The `normalize-ts delete` action allows for cleaning up these `normalized_parsed_log_<group_name>` indices.

---

## Actions

### `normalize-ts run`

Executes the timestamp normalization process.

**Usage:**

```bash
python -m src.logllm normalize-ts run [OPTIONS]
```

**Options (Group Selection - Mutually Exclusive, Required):**

- `-g GROUP`, `--group GROUP`:
  Specify a single group name (e.g., "apache") whose `parsed_log_<group_name>` index should be processed.
- `-a`, `--all-groups`:
  Process all groups found in the Elasticsearch `group_infos` index. The system will iterate through each group and normalize its corresponding `parsed_log_<group_name>` index.

**Common Options for `run`:**

- `-l LIMIT`, `--limit LIMIT`:
  (Optional, primarily for testing) Limits the number of documents processed _per group_. If you process all groups with a limit of 10, it will process up to 10 documents from each group.
- `-b BATCH_SIZE`, `--batch-size BATCH_SIZE`:
  The number of documents to process and then index in each bulk request to Elasticsearch during the normalization. Defaults to `100`.
- `-t THREADS`, `--threads THREADS`:
  (Only applicable when using `--all-groups`) Specifies the number of parallel worker threads to use for processing different groups concurrently. Each thread handles one group at a time. Defaults to `1` (sequential processing of groups).

**Examples:**

1.  **Normalize timestamps for the "apache" group, processing only the first 50 documents for testing:**

    ```bash
    python -m src.logllm normalize-ts run -g apache -l 50
    ```

    This will read from `parsed_log_apache` and write to `normalized_parsed_log_apache`.

2.  **Normalize timestamps for ALL known log groups, using 3 worker threads:**
    ```bash
    python -m src.logllm normalize-ts run --all-groups -t 3
    ```

---

### `normalize-ts delete`

Deletes the `normalized_parsed_log_<group_name>` indices that were created by the `normalize-ts run` command. This is useful for cleaning up or before re-running the normalization from scratch.

**Usage:**

```bash
python -m src.logllm normalize-ts delete [OPTIONS]
```

**Options (Group Selection - Mutually Exclusive, Required):**

- `-g GROUP`, `--group GROUP`:
  Specify a single group name. The command will attempt to delete the `normalized_parsed_log_<group_name>` index.
- `-a`, `--all-groups`:
  Attempt to delete `normalized_parsed_log_<group_name>` indices for all groups found in the `group_infos` index.

**Common Options for `delete`:**

- `-y`, `--yes`:
  If specified, the command will proceed with the deletion without prompting the user for confirmation. **Use this option with caution, as index deletion is irreversible.**

**Examples:**

1.  **Delete the normalized timestamp data for the "hadoop" group. The system will ask for confirmation:**

    ```bash
    python -m src.logllm normalize-ts delete -g hadoop
    ```

    Output: `Are you sure you want to delete normalized indices? This action cannot be undone. (yes/no):`
    Enter `yes` to proceed.

2.  **Delete normalized timestamp data for ALL groups, and skip the confirmation prompt:**
    ```bash
    python -m src.logllm normalize-ts delete --all-groups -y
    ```
